{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "path = \"./Kickstarter_Dataset/\"\n",
    "\n",
    "dataframes = [pd.read_csv(filename) for filename in os.scandir(path) if filename.is_file]\n",
    "\n",
    "result = pd.concat(dataframes).reset_index()\n",
    "\n",
    "result.to_csv(\"./data/kickstarter_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1234176/1234176 [03:39<00:00, 5621.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors detected: 4319\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def find_dict_strings(df, sample_size=5):\n",
    "    \"\"\"\n",
    "    find string dictionary columns in a dataframe\n",
    "\n",
    "    :param df:\n",
    "    :param sample_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sdicts = [0]*len(df.columns)\n",
    "    sample = [random.randint(0, df.shape[0]) for _ in range(sample_size)]\n",
    "    df_sample = df.filter(items=sample, axis=0).reset_index()\n",
    "    for index, row in df_sample.iterrows():\n",
    "        for idx, col in enumerate(df.columns):\n",
    "            if type(df_sample.iat[index, idx]) == str and df_sample.iat[index, idx][0] == '{':\n",
    "                sdicts[idx] = sdicts[idx] + 1\n",
    "    return [df.columns[i-1] for i, item in enumerate(sdicts) if item == sample_size]\n",
    "\n",
    "def strdict_to_dict(x):\n",
    "    \"\"\"\n",
    "    convert string dictionary into dictionary\n",
    "\n",
    "    :param x:\n",
    "    :param errors:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def apply_strdict_to_dict(df):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for i in sd:\n",
    "        df[i] = df[i].apply(lambda x: strdict_to_dict(x))\n",
    "    return df\n",
    "\n",
    "def calculate_errors(df):\n",
    "    \"\"\"\n",
    "    calcaute the overall errors trying to convert str dict to dict\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    with tqdm(total=df.shape[0]*len(sd)) as pbar:\n",
    "        for col in sd:\n",
    "            for index, row in df.iterrows():\n",
    "                if type(df.iloc[index][col]) != dict:\n",
    "                    errors.append(index)\n",
    "                pbar.update(1)\n",
    "\n",
    "    print(f\"Number of errors detected: {len(errors)}\")\n",
    "    return errors\n",
    "\n",
    "def split_dict(df_clean):\n",
    "    \"\"\"\n",
    "    split dictionaries into columns\n",
    "\n",
    "    :param df_clean:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for dict_col in sd:\n",
    "        a = pd.DataFrame(df_clean[dict_col].tolist())\n",
    "        col_names = {i: f\"{i}_{dict_col}\" for i in a.columns}\n",
    "        a.rename(columns=col_names, inplace=True)\n",
    "        dfs.append(a)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "# Find string dicts and calculate errors\n",
    "sd = find_dict_strings(result)\n",
    "result = apply_strdict_to_dict(result)\n",
    "errors = calculate_errors(result)\n",
    "\n",
    "# Filter dataframe by errors\n",
    "df = result.filter(items=errors, axis=0)\n",
    "df.to_csv(\"./data/errors.csv\")\n",
    "\n",
    "# Filter dataframe by clean data\n",
    "df_clean = result[~result.index.isin(errors)]\n",
    "df_clean.to_csv(\"./data/clean_data.csv\")\n",
    "\n",
    "# Split dicts into columns for clean dataframe\n",
    "dfs = split_dict(df_clean)\n",
    "horizontal_concat = pd.concat(dfs, axis=1)\n",
    "\n",
    "# combine split dataframe and clean data and drop old columns\n",
    "df_clean_split = pd.concat([df_clean, horizontal_concat], axis=1)\n",
    "df_clean_split.drop(columns=sd, inplace=True)\n",
    "df_clean_split.to_csv(\"./data/df_clean_split.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}